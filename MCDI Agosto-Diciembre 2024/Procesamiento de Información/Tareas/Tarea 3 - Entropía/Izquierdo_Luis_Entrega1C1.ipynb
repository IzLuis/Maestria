{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1B2. Práctica: Cálculo de entropía\n",
    "\n",
    "### Alumno: **Luis Fernando Izquierdo Berdugo**\n",
    "### Materia: **Procesamiento de Información**\n",
    "### Fecha: **3 de Septiembre de 2024**\n",
    "\n",
    "**Instrucciones**:\n",
    "\n",
    "Preprocesar el texto y convertirlo a minúsculas, quitar acentos y los siguientes caracteres:\n",
    "\n",
    "`;:,.\\\\-\\\"'/()[]¿?¡!{}~<>|«»-—’\\t\\n\\r`\n",
    "\n",
    "1. Calcular la entropía global a nivel de carácter de los documentos text_1 al text_5  de manera independiente. \n",
    "\n",
    "2. Calcular la entropía global a nivel de palabra de los documentos libro_1 y libro_2  de manera independiente. Primero, sin quitar stopwords y luego quitándolas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los textos\n",
    "\n",
    "Para esta actividad, se hizo el procesamiento siguiente:\n",
    "- Pasado de los textos a minúsculas.\n",
    "- Eliminación de caracteres especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "special = \";:,.\\\\-\\\"'/()[]¿?¡!{}~<>|«»-—’\\t\\n\\r\"\n",
    "\n",
    "file = open(\"text_1.txt\", \"r\")\n",
    "text_1 = file.read()\n",
    "file.close()\n",
    "text_1 = text_1.lower()\n",
    "text_1 = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\t\\n\\r]\", \"\", text_1)\n",
    "\n",
    "file = open(\"text_2.txt\", \"r\")\n",
    "text_2 = file.read()\n",
    "file.close()\n",
    "text_2 = text_2.lower()\n",
    "text_2 = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\t\\n\\r]\", \"\", text_2)\n",
    "\n",
    "file = open(\"text_3.txt\", \"r\")\n",
    "text_3 = file.read()\n",
    "file.close()\n",
    "text_3 = text_3.lower()\n",
    "text_3 = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\t\\n\\r]\", \"\", text_3)\n",
    "\n",
    "file = open(\"text_4.txt\", \"r\")\n",
    "text_4 = file.read()\n",
    "file.close()\n",
    "text_4 = text_4.lower()\n",
    "text_4 = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\t\\n\\r]\", \"\", text_4)\n",
    "\n",
    "file = open(\"text_5.txt\", \"r\")\n",
    "text_5 = file.read()\n",
    "file.close()\n",
    "text_5 = text_5.lower()\n",
    "text_5 = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\t\\n\\r]\", \"\", text_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los libros\n",
    "\n",
    "En el caso de los libros, se harán dos procesamientos, uno que incluye quitar stopwords y otro que no, de cualquier manera, ambos siguen el siguiente proceso:\n",
    "- Transformación a minúsculas\n",
    "- Eliminación de acentos\n",
    "- Eliminación de caracteres especiales\n",
    "\n",
    "De igual forma, se descargan las stopwords del módulo nltk y se crea una función para eliminarlas. También se crea una función para eliminar los acentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/izluis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import ssl\n",
    "import unicodedata\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "_STOPWORDS = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text_nostop = []\n",
    "    for word in text.split():\n",
    "        if word in _STOPWORDS:\n",
    "            continue\n",
    "        else:\n",
    "            text_nostop.append(word)\n",
    "    return ' '.join(text_nostop)\n",
    "\n",
    "def remove_accents(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"libro_1.txt\", \"r\")\n",
    "libro_1 = file.read()\n",
    "file.close()\n",
    "libro_1 = libro_1.lower()\n",
    "libro_1_nostop = remove_stopwords(libro_1)\n",
    "libro_1_nostop = remove_accents(libro_1_nostop)\n",
    "libro_1_nostop = re.sub(r\"[\\t\\n]\", \" \", libro_1_nostop)\n",
    "libro_1_nostop = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\r]\", \"\", libro_1_nostop)\n",
    "libro_1 = remove_accents(libro_1)\n",
    "libro_1 = re.sub(r\"[\\t\\n]\", \" \", libro_1)\n",
    "libro_1 = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\r]\", \"\", libro_1)\n",
    "\n",
    "\n",
    "file = open(\"libro_2.txt\", \"r\")\n",
    "libro_2 = file.read()\n",
    "file.close()\n",
    "libro_2 = libro_2.lower()\n",
    "libro_2_nostop = remove_stopwords(libro_2)\n",
    "libro_2_nostop = remove_accents(libro_2_nostop)\n",
    "libro_2_nostop = libro_2_nostop.lower()\n",
    "libro_2_nostop = re.sub(r\"[\\t\\n]\", \" \", libro_2_nostop)\n",
    "libro_2_nostop = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\t\\n\\r]\", \"\", libro_2_nostop)\n",
    "libro_2 = remove_accents(libro_2)\n",
    "libro_2 = re.sub(r\"[\\t\\n]\", \" \", libro_2)\n",
    "libro_2 = re.sub(r\"[;:,.\\-\\\"'/\\(\\)\\[\\]¿?¡!\\{\\}~<>|«»-—’\\r]\", \"\", libro_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inciso 1 - Entropía en Caracteres.\n",
    "Para este caso, la variable aleatoria independiente será la probabilidad de ocurrencia de los caracteres presentes en el texto; entonces la probabilidad que se tomará es la frecuencia del caracter entre el total de los caracteres de cada texto.    \n",
    "\n",
    "Se crea una función para el conteo de caracteres. Esta irá por cada caracter del texto, añadirá uno al total de caracteres en el teto y también añadirá 1 al conteo de caracter individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charCount(text):\n",
    "    conteo = {}\n",
    "    total = 0\n",
    "    for character in text:\n",
    "        total += 1\n",
    "        conteo[character] = conteo.get(character, 0) + 1\n",
    "    return conteo, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el cálculo de frecuencias por cada texto, así como se obtiene el total de caracteres por cada texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_txt1, total_txt1 = charCount(text_1)\n",
    "frecuencia_txt2, total_txt2 = charCount(text_2)\n",
    "frecuencia_txt3, total_txt3 = charCount(text_3)\n",
    "frecuencia_txt4, total_txt4 = charCount(text_4)\n",
    "frecuencia_txt5, total_txt5 = charCount(text_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el cálculo de la entropía, se tomará la frecuencia y el total de caracteres para buscar la probabilidad y también usar la fórmula de la entropía global:\n",
    "\n",
    "### $H(x) = -\\sum_{x \\in X}p(x)log_2p(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calcEntr(freq, total):\n",
    "    entr = 0\n",
    "    for char in freq.values():\n",
    "        prob = char/total\n",
    "        entr -= (prob * math.log2(prob))\n",
    "    return entr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con la función de entropía, se hace el cálculo de esta para cada uno de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La entropía a nivel de carácter del Texto 1 es 3.1681820267348035\n",
      "La entropía a nivel de carácter del Texto 2 es 3.188483436190213\n",
      "La entropía a nivel de carácter del Texto 3 es 3.3242783480628573\n",
      "La entropía a nivel de carácter del Texto 4 es 3.2153472642292873\n",
      "La entropía a nivel de carácter del Texto 5 es 3.265906719965582\n"
     ]
    }
   ],
   "source": [
    "entropia_txt1 = calcEntr(frecuencia_txt1, total_txt1)\n",
    "entropia_txt2 = calcEntr(frecuencia_txt2, total_txt2)\n",
    "entropia_txt3 = calcEntr(frecuencia_txt3, total_txt3)\n",
    "entropia_txt4 = calcEntr(frecuencia_txt4, total_txt4)\n",
    "entropia_txt5 = calcEntr(frecuencia_txt5, total_txt5)\n",
    "\n",
    "print(f\"La entropía a nivel de carácter del Texto 1 es {entropia_txt1}\")\n",
    "print(f\"La entropía a nivel de carácter del Texto 2 es {entropia_txt2}\")\n",
    "print(f\"La entropía a nivel de carácter del Texto 3 es {entropia_txt3}\")\n",
    "print(f\"La entropía a nivel de carácter del Texto 4 es {entropia_txt4}\")\n",
    "print(f\"La entropía a nivel de carácter del Texto 5 es {entropia_txt5}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inciso 2 - Entropía en palabras\n",
    "\n",
    "El procesamiento será bastante similar al de la entropía en caracteres, la principal diferencia será que la variable aleatoria independiente será la probabilidad de ocurrencia de una palabra en el texto.\n",
    "\n",
    "Debido a lo anterior, se creó una función que cuenta el total de palabras en el texto y la frecuencia de cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCount(text):\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    conteo = {}\n",
    "    total = 0\n",
    "    for word in words:\n",
    "        total += 1\n",
    "        conteo[word] = conteo.get(word, 0) + 1\n",
    "    return conteo, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función anterior, se calcula la frecuencia y total de los libros 1 y 2, esto en el caso de tener stopwords y también cuando no las tienen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_libro1, total_libro1 = wordCount(libro_1)\n",
    "frecuencia_libro2, total_libro2 = wordCount(libro_2)\n",
    "frecuencia_libro1_nostop, total_libro1_nostop = wordCount(libro_1_nostop)\n",
    "frecuencia_libro2_nostop, total_libro2_nostop = wordCount(libro_2_nostop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se usará la función de entropía generada previamente para hacer este cálculo en los libros con y sin stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La entropía a nivel de palabras del Libro 1 es 9.21154132057109\n",
      "La entropía a nivel de palabras del Libro 2 es 9.61096251407057\n",
      "La entropía a nivel de palabras del Libro 1 sin stopwords es 11.069996852967849\n",
      "La entropía a nivel de palabras del Libro 2 sin stopwords es 11.653170296257365\n"
     ]
    }
   ],
   "source": [
    "entropia_libro1 = calcEntr(frecuencia_libro1, total_libro1)\n",
    "entropia_libro2 = calcEntr(frecuencia_libro2, total_libro2)\n",
    "entropia_libro1_nostop = calcEntr(frecuencia_libro1_nostop, total_libro1_nostop)\n",
    "entropia_libro2_nostop = calcEntr(frecuencia_libro2_nostop, total_libro2_nostop)\n",
    "\n",
    "\n",
    "print(f\"La entropía a nivel de palabras del Libro 1 es {entropia_libro1}\")\n",
    "print(f\"La entropía a nivel de palabras del Libro 2 es {entropia_libro2}\")\n",
    "print(f\"La entropía a nivel de palabras del Libro 1 sin stopwords es {entropia_libro1_nostop}\")\n",
    "print(f\"La entropía a nivel de palabras del Libro 2 sin stopwords es {entropia_libro2_nostop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en el caso de la **entropía a nivel de carácter**, todos los textos tienen una entropía similar; la cual indica una alta variabilidad en el uso de los caracteres y que no tienen una secuencia predecible, no sigue patrones obvios.\n",
    "\n",
    "Para el caso de **entropía a nivel de palabras**, se puede observar que los libros son similares en entropía en sus dos estados: con y sin stopwords. Un valor de entropía alto para ambos casos indica una gran variedad de palabras en ambos libros, las cuales no se repiten con frecuencia y no tienen una secuencia predecible. Al quitar las stopwords el valor aumenta ya que se quitan palabras que no tienen un peso significativo y tambié una gran cantidad de palabras repetidas, lo cual aumenta la variabilidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
