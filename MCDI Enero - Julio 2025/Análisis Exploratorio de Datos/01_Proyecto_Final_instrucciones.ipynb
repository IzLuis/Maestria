{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec29614-bebf-4274-87b1-87ba142b9995",
   "metadata": {},
   "source": [
    "# **Proyecto Final**\n",
    "\n",
    "**Materia**: Análisis Exploratorio de Datos\n",
    "\n",
    "**Profesor**: Miguel Ángel Porta García"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657062e-299a-455b-9800-a989011ba1fe",
   "metadata": {},
   "source": [
    "### **Introducción**\n",
    "##### **Abalone dataset**\n",
    "\n",
    "\n",
    "##### ¿Qué es un abulón?\n",
    "\n",
    "\n",
    "Los abulones son caracoles marinos. Su taxonomía los ubica en la familia Haliotidae, que contiene solo un género, Haliotis, que alguna vez contenía seis subgéneros. Estos subgéneros se han convertido en representaciones alternativas de Haliotis. El número de especies reconocidas en todo el mundo varía entre 30 y 130, con más de 230 taxones a nivel de especie descritos. El tratamiento más completo de la familia considera válidas 56 especies, con 18 subespecies adicionales.\n",
    "\n",
    "Este análisis evalúa el conjunto de datos de abulón e intenta aplicar una técnica de  clustering para ver si los modelos predictivos se pueden mejorar con los agrupamientos. Este análisis concluye que si se aplica un buen clustering, se puede mejorar el rendimiento de un modelo predictivo.\n",
    "\n",
    "El conjunto de datos de abulón es antiguo y la edad (o la cantidad de anillos) se predice a partir de características que se pueden medir con mayor facilidad. \n",
    "\n",
    "Se compone de los siguientes atributos:\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Nombre</th>\n",
    "<th>Tipo de datos</th>\n",
    "<th>Medidas</th>\n",
    "<th>Descripción</th>\n",
    "</tr>\n",
    "<tbody>\n",
    "<tr><td>Sexo</td> <td>nominal</td> <td></td> <td>M, F e I (infante)</td></tr>\n",
    "<tr><td>Longitud</td> <td>continua</td> <td>mm</td> <td>Medida de la concha más larga</td></tr>\n",
    "<tr><td>Diámetro</td> <td>continuo</td> <td>mm</td> <td>perpendicular a la longitud</td></tr>\n",
    "<tr><td>Altura</td> <td>continuo</td> <td>mm</td> <td>con carne en cáscara</td></tr>\n",
    "<tr><td>Peso entero</td> <td>continuo</td> <td>gramos</td> <td>abulón entero</td></tr>\n",
    "<tr><td>Peso descascarado</td> <td>continuo</td> <td>gramos</td> <td>peso de la carne</td></tr>\n",
    "<tr><td>Peso de las vísceras</td> <td>continuo</td> <td>gramos</td> <td>peso de la tripa (después del desangrado)</td></tr>\n",
    "<tr><td>Peso de la cáscara</td> <td>continuo</td> <td>gramos</td> <td>después de secarse</td></tr>\n",
    "<tr><td>Anillos</td> <td>entero</td> <td></td> <td>+1,5 da la edad en años</td></tr>\n",
    "</tbody>\n",
    "</thead>\n",
    "</table>\n",
    "\n",
    "En este estudio se analizaran cada uno de estos atributos, así como las relaciones entre ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571f5ae",
   "metadata": {},
   "source": [
    "\n",
    "## Instrucciones Generales\n",
    "\n",
    "Este notebook contiene una serie de pasos detallados para analizar el conjunto de datos **abalone_new.csv**, que proporciona información sobre dimensiones físicas, peso y edad de los abulones. A continuación, se presentan las instrucciones a seguir en el proyecto final.\n",
    "\n",
    "1. Lee atentamente las instruciones y relaiza el análsis exploratorio del dataset de \"abulone_new.csv\"\n",
    "2. Elabora un resumen ejecutuvo de los hallazgos obtenidos\n",
    "    a. Introducción\n",
    "    b. Analisis de las proyecciones\n",
    "    c. Conclusiones\n",
    "    d. Referencias\n",
    "3. Guarda tu archivo en formato .iypnb, de la siguiente manera: Actividad_1_Nombre_Apellido.pdf\n",
    "\n",
    "4. Entrega tu actividad en el espacio correspondiente.\n",
    "\n",
    "## Instrucciones del análisis\n",
    "\n",
    "### 📌 1. Preparación del entorno, instalación y configuración inicial\n",
    "\n",
    "* Abre un entorno Jupyter Notebook o JupyterLab.\n",
    "* Crea un nuevo notebook para Python 3.\n",
    "* Instala las bibliotecas necesarias ejecutando la siguiente celda:\n",
    "\n",
    "```bash\n",
    "!pip install ydata-profiling pyclustertend seaborn numpy pandas matplotlib scikit-learn\n",
    "```\n",
    "### 📌 2. Introducción y Contexto\n",
    "\n",
    "* Familiarízate con el contexto y los objetivos del análisis:\n",
    "- Los abulones son caracoles marinos cuyo número de anillos indica su edad.\n",
    "- El objetivo del análisis es determinar si se puede mejorar la precisión de modelos predictivos sobre la edad mediante técnicas de clustering.\n",
    "\n",
    "### 📌 3. Importación de Librerías necesarias\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from ydata_profiling import ProfileReport\n",
    "from pyclustertend import vat, ivat, hopkins\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "# Configuración de visualización\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "```\n",
    "\n",
    "### 📌 4. Carga del conjunto de datos\n",
    "\n",
    "* Descarga el archivo `abalone_new.csv` y cárgalo en un Dataframe:\n",
    "\n",
    "Nota: Asegúrate de tener el archivo `abalone_new.csv` en el mismo directorio que el notebook.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('abalone_new.csv')\n",
    "```\n",
    "\n",
    "### 📌 5. Análisis Exploratorio del dataset `abalone_new.csv` \n",
    "\n",
    "1. 🔍 Información general del dataset\n",
    "2. 📈 Estadísticas descriptivas para columnas numéricas\n",
    "3. 🚫 Verificar valores nulos\n",
    "   * Muestra el número de renglones con valores faltantes para cada columna\n",
    "4. 🔄 Verificar duplicados\n",
    "5. Distribución de las variables categóricas \"Maturity_Level\" y \"Sex\"\n",
    "6. 📈 Matriz de correlación (solo columnas numéricas)\n",
    "\n",
    "\n",
    "### 📌 6. Limpieza de dataset\n",
    "1. 🔍Detección y manejo de valores faltantes\n",
    "    * Identifica valores faltantes\n",
    "    * Selecciona solo columnas numéricas antes de imputar\n",
    "    * Guardar los tipos de datos originales\n",
    "    * Imputar valores faltantes con la media\n",
    "    * Convertir los datos imputados a su tipo original y redondear a 5 decimales\n",
    "2. Eliminación de columnas con varianza cero\n",
    "3. Detección y remoción de outliers\n",
    "4. Eliminación de valores duplicados\n",
    "5. Guardar el dataset procesado\n",
    "\n",
    "### 📌 7. Procesamiento del dataset\n",
    "\n",
    "1. Carga el nuevo dataset que generaste en el paso anterior `abalone_processed.csv`\n",
    "\n",
    "### 📌 8. Análisis Exploratorio del dataset `abalone_processed.csv`\n",
    "\n",
    "1. 🔍 Información general del dataset\n",
    "2. 📈 Estadísticas descriptivas para columnas numéricas\n",
    "3. 🚫 Verificar valores nulos\n",
    "     Muestra el número de renglones con valores faltantes para cada columna\n",
    "4. 🔄 Verificar duplicados\n",
    "5. Distribución de las variables categóricas \"Maturity_Level\" y \"Sex\"\n",
    " 6. 📈 Matriz de correlación (solo columnas numéricas)\n",
    "\n",
    "### 📌 7. Análisis de correlaciones\n",
    "\n",
    "1. Elabora un análisis de correlaciones:\n",
    "\n",
    "    * Puedes utilizar un gráfico de heatmap para la visualización de las correlaciones\n",
    "    * Verifica si todas las correlaciones son significactivas y en todo caso elimina las variables que no lo sean\n",
    "    * Verifica con una nueva gafica de heatmap que las relaciones son significativas\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_encoded.corr(), annot=True, cmap='crest')\n",
    "plt.title(\"Mapa de correlación\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 📌 8. Análisis de Tendencia de Clustering\n",
    "\n",
    "1.  Calcula el estadístico de Hopkins para verificar la tendencia al clustering:\n",
    "\n",
    "```python\n",
    "hopkins_stat = hopkins(df_scaled, df_scaled.shape[0])\n",
    "print(\"Hopkins Statistic:\", hopkins_stat)\n",
    "```\n",
    "\n",
    "2.  Evalúa visualmente usando VAT (Visual Assessment of Cluster Tendency) e iVAT:\n",
    "\n",
    "```python\n",
    "vat(df_scaled)\n",
    "plt.title('Visualización VAT')\n",
    "plt.show()\n",
    "\n",
    "ivat(df_scaled)\n",
    "plt.title('Visualización iVAT')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 📌 9. Análisis de reducción de dimensionalidad (PCA)\n",
    "\n",
    "1. Realiza un análisis de PCA para reducir dimensiones:\n",
    "\n",
    "    Considera:\n",
    "    * 📉 Cálculo de Varianza Explicada\n",
    "    * 📈 Gráfico de Varianza Explicada Acumulada\n",
    "    * Grafico heatmap de los componentes \n",
    "    * 🔍 Verificar valores atípicos antes de la transformación\n",
    "    * 🔄 Normalización de datos\n",
    "    * ⚡ Aplicar PCA\n",
    "    * 🔥 Aplicar KPCA con optimización de parámetros\n",
    "    * 🚀 Prueba de otro kernel para comparar resultados\n",
    "    * 📊 Graficar comparaciones\n",
    "        1️⃣ Espacio Original\n",
    "        2️⃣ Proyección con PCA\n",
    "        3️⃣ Proyección con KPCA (RBF)\n",
    "        4️⃣ Espacio Reconstruido después de KPCA\n",
    "\n",
    "```python\n",
    "pca = PCA(n_components=2)\n",
    "....\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA del dataset de abulones')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Investiga sobre las siguientes proyecciones (10-12). De acuerdo a lo que hayas encontrado, elige una de estas proyecciones para comparar contra la proyección de PCA:\n",
    "\n",
    "##### 📌 10. Proyección con t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "\n",
    "##### 📌 11. Proyección con Isomap (Isometric Mapping)\n",
    "\n",
    "##### 📌 12. Proyección con UMAP (Uniform Manifold Approximation and Projection)\n",
    "\n",
    "### 📌 13. Modelo de clasificación usando k-Nearest Neighbors (k-NN)\n",
    "\n",
    "Este análisis aplica un modelo de **clasificación con k-Nearest Neighbors (k-NN)** sobre el conjunto de datos `abalone_processed.csv`, usando como variable objetivo el número de anillos (`Rings`). \n",
    "\n",
    "1. Importar Librerías\n",
    "    * `pandas`, `numpy` para manipulación de datos.\n",
    "    * `sklearn.model_selection` para separación de datos y validación cruzada.\n",
    "    * `StandardScaler` para normalización.\n",
    "    * `LabelEncoder` para codificación de variables categóricas.\n",
    "    * `KNeighborsClassifier` para el modelo de clasificación.\n",
    "    * `matplotlib` y `seaborn` para visualización.\n",
    "\n",
    "2. Cargar la base de datos\n",
    "    * Se utiliza el archivo `abalone_processed.csv` como fuente de datos.\n",
    "    * La columna `Sex` (categórica) es codificada a valores numéricos con `LabelEncoder`.\n",
    "    * Si la columna `Maturity_Level` existe, también se codifica.\n",
    "\n",
    "\n",
    "3. Preparación de los datos\n",
    "    * Se separan las variables independientes (`X`) de la variable objetivo (`y = Rings`).\n",
    "    * Se filtran solo las columnas numéricas en `X`.\n",
    "    * Se normalizan las características usando `StandardScaler`.\n",
    "\n",
    "4. División de los datos\n",
    "    * Los datos se dividen en conjuntos de entrenamiento (80%) y prueba (20%) con `train_test_split`.\n",
    "\n",
    "5. Entrenamiento del modelo k-NN\n",
    "    * Se entrena un modelo de k-Nearest Neighbors con `k = 5`.\n",
    "    * Se evalúa el modelo con `accuracy_score` sobre el conjunto de prueba.\n",
    "\n",
    "6. Validación cruzada\n",
    "    * Se realiza validación cruzada con 5 pliegues (`cross_val_score`) para obtener una evaluación más robusta del modelo.\n",
    "    * Se imprime el score de cada pliegue y el promedio general de precisión.\n",
    "\n",
    "7. Visualización de la variable objetivo\n",
    "    * Se muestra la distribución del número de anillos (`Rings`) usando `sns.histplot()`.\n",
    "\n",
    "\n",
    "### 📌 14. Evaluación de Modelos Predictivos por Cluster\n",
    "\n",
    "1. Evalúa la mejora en predicción usando Random Forest\n",
    "\n",
    "```python\n",
    "for cluster in df['cluster'].unique():\n",
    "    cluster_data = df[df['cluster'] == cluster]\n",
    "    X = cluster_data.drop(['rings', 'cluster'], axis=1)\n",
    "    y = cluster_data['rings']\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    predictions = model.predict(X)\n",
    "    print(f'Cluster {cluster} MAE:', mean_absolute_error(y, predictions))\n",
    "```\n",
    "\n",
    "### 📌 15. Interpretación\n",
    "\n",
    "* Interpreta los gráficos y redacta conclusiones acerca de los clusters formados.\n",
    "\n",
    "\n",
    "#### **IMPORTANTE:** Realiza los pasos 13-15 pero utilizando las proyecciones (PCA y la que hayas escogido entre 10-12)\n",
    "\n",
    "\n",
    "### 📌 16. Conclusiones\n",
    "\n",
    "* Elbora las conlcusiones sobre los patrones observados y la efectividad del clustering para mejorar predicciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e8119-f2e8-4e4c-b16a-5f6cf13ce188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
